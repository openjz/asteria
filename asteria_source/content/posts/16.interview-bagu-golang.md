---
title: "面试八股-golang"
date: 2022-10-07T18:41:32+08:00
draft: false

tags: ["面试", "golang"]
categories: ["编程"]
---

## golang

部分内容参考[《go 程序员面试笔试宝典》](https://golang.design/go-questions/)

### go 有什么特点

特性

- 协程
- 静态编译，编译出的可执行文件体积小
- 有 runtime、垃圾回收、反射
- 指针

和其他语言相比

- go 作为静态编译语言，和 C/C++相比，go 有 runtime，有垃圾回收，有反射
- go 作为有 runtime 的语言，和 java 相比，是 go 静态编译的
- go 支持指针操作

### 引用类型

- 说明，go 中实际上没有引用这个机制，go 只有值传参，没有所谓的引用传参，我们只是用“引用”来形容一种现象，即传参后，对参数的修改会影响到原变量
- 6 种，slice、map、channel、指针、函数、interface
- 引用类型的零值是 nil
- 数组和结构体不是引用类型，它们的零值是其所有元素和成员的零值

### 切片（slice）

- 切片和数组
  - 切片是对数组的引用，切片的底层数据结构是数组。
    - 切片的长度是切片引用部分的长度，切片的容量是从引用起点到底层数组末尾的长度
  - 切片能扩容，数组不能
  - 切片如何扩容
    - 追加元素时发现数组已满会引起扩容
    - 扩容是给切片重新分配一个更大的数据，并将数据迁移过去
    - 扩容后会预留一定的 buffer，以免每次追加元素都扩容
    - 扩容策略：
      > 当原 slice 容量小于 1024 的时候，新 slice 容量变成原来的 2 倍；原 slice 容量超过 1024，新 slice 容量变成原来的 1.25 倍以上（有一个计算公式）。
- **切片实际上上是一个结构体，因此，把切片作为参数传递的时候，如果修改它的底层数组，会影响原切片，但是如果切片发生了扩容，是直接把底层数组给换了，是不会影响到原切片的**
- 切片不能比较

### map

- map 底层是一个 hash 表，链式 hash，每个 hash 位置指向一个链表，每个链表节点长度为 8（能放 8 个 key-value 对）
- **map 实际上是一个指向底层哈希表的指针，因此把 map 作为参数传递后，对参数做的修改都会影响原 map**
- map 遍历是无序的，每次遍历的顺序不一样（因为对 hash 位置的遍历是随机的）
- map 扩容
  - 扩容不是一个立即完成的操作，而是会持续一段时间，每次最多搬运两个 hash 链
  - 两种扩容场景
    1. 所有的节点都快满了，这时要双倍扩容（扩容后的 hash 空间是原来的两倍），并且要重新计算元素的 hash 值（rehash）
    2. 元素总数很少，节点数量过多，map 退化为链表，这时要等量扩容，扩容后 hash 空间数量和原来相等，只是把数据存储变紧凑了。
- 不要用 float 做 key（语法上是可以的，因为 float 可比较），浮点数的精度问题会导致很多诡异的情况。
- map 不是并发安全的，sync.map 是并发安全的
- 无法对 map 的 key 或 value 进行取址
- 不能直接比较两个 map，只能通过遍历比较

### 接口

- 接口的作用
  - 用于实现继承和多态
- **`T`和`*T`是两个类型，用`T`实现了一个接口，并不能认为`*T`也实现了**。
  - 结论，**实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；而实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法**
  - 换句话说，值类型实现了接口 A，相当于指针类型也实现了接口 A；指针类型实现了接口 A，不会使值类型也实现了接口 A
- 类型断言的作用
  1. 提取动态值
  2. 转换接口类型
  3. 判断动态值是否能转换为某个类型（利用类型断言返回的 bool）
  4. 放在switch语句中简化判断结构

### go runtime

- go runtime 位于应用程序和操作系统之间
  - 负责应用程序的内存分配、垃圾回收、协程调度、channel 通信
  - 负责创建 os 线程、调用 system call

### go 的协程（goroutine）

- 协程是什么
  - 和线程、进程一样是一种并发单位
- 和系统线程相比
  - 更细粒度，线程的栈空间是固定的，而且比较大（linux 下为 8MB），而 goroutine 初始栈大小为 2KB，按需扩缩容，无上限
  - 上下文切换开销小，线程运行在内核态，而协程运行在内核态
  - go 协程没有供程序员访问的标识，而线程都有线程号，go 不鼓励类似 threadlocal 这样的东西
- **goroutine 是如何调度的**
  - goroutine 由 go runtime 的 scheduler 调度
  - goroutine 运行在系统线程上，是一种 m:n 模型
  - 线程数通过 GOMAXPROCS 变量调整，默认的系统线程数是物理机的 cpu 核数

### goroutine 调度

- go 调度器的最终目的是把 g 尽量均匀的分配到 m 上执行，兼顾公平和效率
- gmp 模型，go 使用三种基础的结构体实现 goroutine 的调度。
  - g 代表一个 goroutine，包含：goroutine 栈、状态、指令地址（PC 寄存器的值）
  - m 代表一个内核线程，包含正在运行的 goroutine
  - p 代表一个虚拟的 processer，维护一个 runnable 状态的 g 队列，m 需要获得 p 才能运行 g
- 存放 g 的队列有两类，GRQ（全局可运行队列）和 LRQ（本地可运行队列），每个 p 都要关联一个 LRQ。
- go 设计的早期没有 p 和 LRQ，只有 g、m 和 GRQ，每次调度执行一个 g 都要对 GRQ 上锁，效率低下。**p 和 LRQ 的设计是为了提高调度的效率。**
- **工作窃取**，如果一个 p 的 LRQ 中已经没有 g，GPQ 中也没有 g，p 会从别的 p 中“偷”一些 g 过来执行
- os 的线程调度是抢占式调度，而 goroutine 的调度是协作式调度（无法硬件中断），但调度是由 runtime 负责的，对用户来说，仍可将 goroutine 的调度视为抢占式调度
  > 协作式调度依靠被调度方主动放弃执行；抢占式调度则依靠调度器强制中断被调度方的执行
- g 的三种状态，和线程类似
  - waiting，等待状态（有时候被称为阻塞状态），由等待网络数据、硬盘 io、等待获取锁、系统调用、sleep
  - runnable，可执行状态（就绪状态）
  - running，运行状态
- m 只有两种状态，自旋状态（工作状态）和非自旋状态（休眠状态），m 会因为找不到工作、gc 等原因进入非自旋状态，其他时间都处于自旋状态。
- main goroutine 退出时会调用 exit(0)退出进程

### channel

- channel 解决什么问题
  - channel 用来在两个 goroutine 之间传递数据，类似一个FIFO队列
  - 解决协程之间的并发同步问题
  - 原则，不通过共享内存来通信，而是通过通信共享内存
  - 是一种比锁层次更高的同步工具
- 从一个关闭且缓冲区数据读完的 channel 中仍能取到数据，只不过是零值
- 操作 channel 的情况总结
  |操作| nil channel |closed channel |not nil, not closed channel|
  |---|---|---|---|
  |close |panic |panic |正常关闭
  |读 <- ch| 阻塞| 缓冲区如果还有数据，会正常读取数据，否则读到对应类型的零值| 阻塞或正常读取数据。|缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞|
  |写 ch <-| 阻塞| panic| 阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞
- 使用时要注意防止资源泄露，比如有若干 goroutine 处于阻塞状态，而 channel 的状态一直没有得到改变
- channel 的应用
  - 解耦生产者和消费者
  - 广播停止信号
  - 定时
  - 控制并发数，把令牌放入缓冲区
- channel的底层实现是一个循环链表，记录了两个指针，读指针和写指针，利用一个mutex保证并发安全，保存两个协程队列，一个记录接收协程队列，一个记录发送协程队列
  - 如果有协程需要读写channel时，先加锁，完成数据copy，然后解锁
  - 如果buffer满了，有goroutine需要写怎么办，channel会调用调度器，让出goroutine（G1）在p上的执行权，并且将G1的指针和数据挂到发送队列上去，一旦有goroutine读数据，channel就会将等待队列的G1拿出，将其数据copy到buffer中，并通知调度器唤醒G1，然后调度器就把G1放到runnable队列中去

### context

- context 是什么
  - context 一般翻译成上下文，用来在 goroutine 之间传递上下文信息，包括停止信号、超时时间、截止时间、key-value 数据
  - context 几乎是并发控制和超时控制的标准做法，很多接口都加上了 context 参数
  - context 是一个接口，标准库实现了一些具体的 context 类型，包括 emptyCtx、valueCtx、cancelCtx、timerCtx，还有两个全局变量 background 和 todo
  - 所有 context 会组成一个树状结构（只不过指向和树是相反的，子 context 指向父 context）
- 如何取消 context
  - 父 context 持有一个 channel，可以对所有子 context 广播取消信号，一般会让每个协程携带一个 context，这样就可以把协程也组织成树状结构，父协程可以在请求超时、请求失败时及时向子协程发出终止信号，子协程通过调用 Done()方法获取 channel，并监听 channel 的取消信号
- 如何查找 value
  - 从自己开始，顺着父 context，层层向上找

### reflect

- 什么是反射
  - 反射是一种程序在运行过程中观察自己、修改自己的一种机制，而且这种观察和修改和编译期间做不到的
- 什么时候用反射
  - 不知道参数类型的时候
- 慎用反射的理由
  - 反射会让代码可读性降低
  - 反射性能差

### 指针

- 普通指针（\*T），不能参与运算，不同类型不能比较，不能相互转换
- unsafe.Pointer 相当于一个通用指针，能在不同类型之间转换。
- uintptr 可以对指针进行算术运算，但是不会对指向的变量有引用语义，换言之，即使 uintptr 还存在，它指向的变量还是有可能被 gc（他就像 c 里面的指针）

### go 堆和栈

go 对程序员隐藏了堆和栈的概念，变量分配在栈上还是堆上不取决于变量定义的位置和方法。编译器会对程序进行逃逸分析，如果一个变量在函数之外被引用了，那这个变量会被创建在堆上，否则在栈上

### 垃圾回收（GC）

- gc是回收堆内存的，而不是栈内存，栈内存在函数调用结束后就释放掉了不用专门回收
- 垃圾回收机制有两种，追踪式 GC 和引用计数式 GC，go 是追踪式 GC。
  - 引用计数式GC，C++的shared_ptr就是一个典型的引用计数式资源回收
    - 好处是不需要额外的gc任务，并且程序不用暂停
    - 坏处是会出现循环引用，而且对象增加和减少引用时会增加大量计算
  - 追踪式GC，是判断一个对象是否可达，如何判断一个对象是否可达，第一步，找出所有全局变量和函数栈中的变量，标记为可达，然后通过回溯的方式把所有可达的对象标记出来，那剩下的就是不可达的
- go 的 GC 算法是三色标记法
  - 三色标记法是一种追踪式gc，它主要是为了解决gc会让整个程序停止的问题。其原则是它把堆中的对象根据它们的颜色分到不同集合里面。
    - 黑白灰三色对象，初始全部都为白色对象（表示未检查过，是潜在垃圾）
    - 每检查到一个白色对象，将其变为灰色，表示已经检查了这个对象，但是没有检查它的子对象
    - 如果一个对象的所有直接子对象都被检查到了，就把它变成黑色
    - 直到所有的灰色对象被清空，这时剩下的白色对象就可以被回收了
  - 三色标记的特点是可以并发执行，依靠的是go的写屏障计数，这像是一个钩子方法，能够在创建对象的同时将其标记为灰色（保证不会让一个黑色对象直接指向一个白色对象）
- 内存泄漏有两种
  - 对不再使用的内存一直有引用
  - goroutine 泄露（goroutine 一直阻塞在一个 channel 上）

### go 工具

- GOROOT 和 GOPATH 的区别
  - GOROOT 是 go 安装的位置
  - GOPATH 的作用是提供一个可以寻找 go 源码的路径，GOPATH 目录下需要包含 src、pkg、bin 三个目录，src 存放源文件，pkg 存放编译产出（库文件），bin 存放可执行文件

## 系统

### 基础

- 什么是协程
- 进程和线程的区别
  - 进程是资源分配的基本单位，线程是调度的基本单位
  - 线程属于进程，一个进程包含多个线程
  - 进程间相互隔离，不共享资源，一个挂了不影响其他的，线程共享进程资源，一个线程挂了整个进程全挂
  - 进程上下文切换开销比线程大
  - 进程间通信方式和线程不同
  - 进程存在父子关系，线程不存在
- 死锁的四个条件
  - 互斥（资源具有互斥性）
  - 持有且等待
  - 不可剥夺
  - 循环等待
- 进程/线程调度算法
  - 抢占式调度，内核强行调度
  - 非抢占式调度，进程主动让出执行权
  - 调度算法
    1. 先来先服务，对长作业有利，但是对短作业不利
    2. 最短作业优先，会发生饥饿现象
    3. 高响应比优先，同时将要求服务时间和等待时间算入优先级，照顾到了长进程
    4. 时间片轮转
    5. 最高优先级调度，静态优先级和动态优先级（Linux的nice值和pr值）
    6. 多级反馈队列调度，多个队列，队列优先级从高到低，高优队列时间片最短，低优队列时间片最长，新进程先进入高优队列，如果在时间片内没执行完，就进入
- 
- 页面置换
  1. 先进先出
  2. 最近最久未使用（LRU）
  3. 最不常用（LFU）
  4. 时钟页面置换，对每个内存页加个访问位，被访问到置位1，新页面为0，页面置换时扫描，访问位为0时换出，访问位为1时不换出，但将其改为0。
  5. 最佳页面置换，无法实现的算法，置换未来最长时间不访问的页面

### linux

- `ps`，查看进程状态
  - ps命令参数分三种风格，带“-”的是unix风格，不带的是bsd风格，“--”是GNU风格，最坑的是不同风格的输出不一样
    > 比如，ps -aux 和 ps aux其实完全不一样，-aux是想打印用户x的所有进程，如果用户x不存在，ps会帮你把命令改写成ps aux
  - 查看所有进程
    - ps -e，ps -ef，ps -eF，ps -ely
    - ps aux，ps ax
  - 查看进程树，ps -ejH，ps axjf
  - `ps aux`，`x`列出没有控制终端的进程，`u`列出更多信息（用户、CPU、内存等）、`a`列出所有用户的进程
  - ps aux字段含义
    ```
    USER          进程所有者的用户名
    PID           进程ID（Process ID）
    START         进程激活时间
    %CPU          进程的cpu占用率
    %MEM          进程使用内存的百分比
    VSZ           进程使用的虚拟内存大小，以K为单位
    RSS           驻留空间的大小。显示当前常驻内存的程序的K字节数。
    TTY           与进程关联的终端（tty）
    STAT          进程状态，包括下面的状态： 
          D    不可中断的sleep，通常在IO
          R    正在运行，或在可运行队列中的进程
          S    可中断的sleep状态，通常是在等待事件将其唤醒
          T    暂停状态（ctrl+z）
          t    由于调试器跟踪而暂停
          Z    僵尸进程
          W    进入内存交换（从内核2.6开始无效）
          X    正在被销毁（非常短暂，几乎不可能被看到）
      状态描述
          <    高优先级
          N    低优先级
          L    有些页被锁进内存
          s    session leader（会话首进程）
          +    在前台进程组中
          l    多线程，克隆线程
    TIME          进程使用的总CPU时间
    COMMAND       被执行的命令行
    NI            进程的优先级值，较小的数字意味着占用较少的CPU时间
    PRI           进程优先级。
    PPID          父进程ID
    WCHAN         进程等待的内核事件名  
    ```
    >linux中的虚拟内存不是指swap，是指进程的逻辑地址空间，只有实际访问到的内存会被映射到物理内存，这部分物理内存叫常驻内存。
- `grep`，文本搜索，`-c`：仅显示找到的行数，`-n`：显示行号，`-i`：忽略大小写，`-v`：反向搜索（搜索不包含指定字符串的行）
- `crontab`，定时任务，格式，“分 时 日 月 星期 命令”
- `free`，查看内存，默认按KB查看，-b，按字节展示，-k，按KB展示，-m，按MB展示，-g，按GB展示，-h，按适当的单位展示，-s N，隔N秒输出一次
  - 第一行是内存，第二行是swap
  - total是总内存，used是已使用的内存，free是未使用的内存，shared是共享使用的内存，buff/cache是buffer和cache使用的内存，available是应用程序可用的内存。
  - 和free相比，available算入了page cache
    >buffer是指buffer cache，buffer cache是存储在内存中的文件块（一个文件块大小不能超过内存页大小）
    >
    >cache是指page cache，一般翻译成页高速缓存，是用内存做磁盘缓存，包含对普通文件、块设备文件、内存映射文件的缓存。对块设备文件的缓存就是buffer cache。
  - free命令来自`/proc/meminfo`文件，直接查看这个文件也行
- `top`，实时查看当前系统中的进程状态
  - 第一部分，系统总体状况
    - 第一行，当前时间，运行时间（up 2 day），当前用户数量，系统在之前1分钟、5分钟、15分钟的平均负载
    - 第二行（进程信息），系统中的进程总数，正在运行的进程数，睡眠的进程数，正在停止的进程数，僵尸进程数。
    - 第三行（cpu占用），用户模式，系统模式...
    - 第四、五行（内存信息，和free命令差不多）
  - 第二部分，各个进程的详细信息，以下是各字段含义
    ```
    PID — 进程id
    USER — 进程所有者
    PR — 进程优先级，值越小优先级越高
    NI — nice值。静态优先级，值越小优先级越高
    VIRT — 进程使用的虚拟内存总量，单位kb。
    RES — 常驻内存大小，单位kb。
    SHR — 共享内存大小，单位kb
    S —进程状态。
    %CPU — cpu占用
    %MEM — 内存占用
    TIME+ — 进程使用的CPU时间总计，最小单位是秒
    COMMAND — 命令
    ```
- `tar`，压缩和打包命令
- `netstat`，查看网络状态
  - 按域查看，-4，-6，-A <域>，--域，具体的域有inet（ipv4）、inet6（ipv6）等等
  - 按socket查看，-t，--tcp，-u，--udp，-x，--unix，-w，--raw等等
  - -a，查看所有socket（默认只显示建立连接的），-n，显示ip而不是域名，-p，显示pid（只有当前用户的进程号），-o，显示timers，-l，只显示监听，-e，显示用户和inode
  - -r，查看路由表，-i，查看网卡，-s，查看网络连接统计数据
  - -c，持续输出
- `ping`，用于检测和目标主机的网络连接
  - 利用icmp协议的echo信息检查目的主机的可达性、延迟、报文丢失情况
    >icmp协议（网络控制报文协议）是一种差错报告和信息查询协议，当数据传输出现错误时，利用icmp协议通知源主机数据传输出错，也可以利用icmp查询一些信息。
    >
    >icmp报文放在ip报文的数据部分中，从报文结构上来看，icmp是ip的上层协议，但是icmp承担了ip层的任务，因此我们将icmp视为ip层协议
- `traceroute`，用于查看到目的主机的路由路径
  - traceroute有三种实现，icmp、udp、tcp
  - udp，`traceroute xxx`或`traceroute -T xxx`，traceroute默认使用udp。向目的主机发送很多不同TTL的UDP报文，并访问一个大于30000的端口号，如果在传输到某个路由器时TTL的值减为0，则路由器回送一个超时的ICMP报文，如果报文到达了目的主机，则目的主机会回送一个端口不可达的ICMP报文。
  - icmp，`traceroute -I xxx`。利用icmp echo实现，向目的主机发送很多不同TTL的ICMP echo请求报文，如果在传输到某个路由器时TTL的值减为0，则路由器回送一个超时的ICMP报文，如果报文到达了目的主机，则目的主机会回送一个ICMP echo响应报文。
    >TTL通常是指“报文最大生存时间”，但是在icmp里，TTL就是指路由器的跳数
  - tcp，`traceroute -T xxx`
  - 问题
    - 使用时看不到目的主机，使用udp协议时可能会出现这种情况，原因是目的主机没开放udp服务，回送不了“端口不可达”icmp报文
    - 使用时看不到中间路由器，可能是因为中间路由器不支持回送超时icmp报文
  - windows下的tracert使用icmp实现
- `kill`，按进程id发信号
  - kill -l 可以查看所有信号的编号
  - kill默认发送的是TERM信号（编号15），会要求进程退出，进程在退出前可以做一些善后工作
  - kill -9 发送的是KILL信号，让进程强制退出，不给进程善后的机会
- `killall`，按进程名字发信号
- `pkill`，筛选进程并发信号
- `pgrep`，筛选进程
- linux的硬连接和软连接
  - 一个linux文件元信息分为两部分，一部分是文件名，另一部分是inode，inode存放了文件的属性、数据块指针等
  - 软连接，软连接类似于windows中的快捷方式，软连接不会对inode有真正的引用
  - 硬连接是对inode的真正引用，只有把硬连接全部删除，文件才会被删掉

### linux的五种I/O模型

- 阻塞式I/O
  - 普通的IO操/作都是阻塞式I/O
  - 阻塞式I/O可能会被永久阻塞，比如网络连接一直没有数据过来
- 非阻塞式I/O
  - 非阻塞式I/O没有永久阻塞的风险，如果I/O操作因为不满足条件而无法完成，调用会立即出错返回
  - 误区1，阻塞式I/O和异步I/O混为一谈
    - 非阻塞是强调调用不会进入阻塞状态，调用本身和发起调用的程序流程是顺序的，是同步的，调用一旦返回，这次调用就已经完成了。
    - 异步I/O强调的是I/O操作和发起调用的流程同时进行，异步调用发起后立即返回的不是最终结果，而是告诉调用者一个“已收到”信息，最终执行完成后通过某种手段通知调用方执行结果。
  - 误区2，非阻塞式I/O会造成进程或线程一直占用CPU
    - 占用CPU的不是非阻塞式I/O，而是程序员轮询非阻塞式I/O造成的（比如写个死循环不停地调用非阻塞式I/O，直到成功为止）
- 信号驱动I/O
  - 内核用SIGIO这个信号通知进程有事件到达，是一种异步通知机制
  - 一般是UDP通信会使用这个I/O模型，原因是系统统一使用SIGIO这一个信号表示I/O事件，UDP只有两个事件会发出这个信号（数据到达和发生错误），比较容易判断和处理，而TCP有一堆事件会发出这个信号，而且信号发出过于频繁，没法采用这个I/O模型
- I/O多路复用
  - 同时从多个文件描述符里读数据，可以在同一个线程内一个循环搞定，降低程序复杂度
  - 通过 I/O 复用函数向内核注册一组文件描述符，当某个文件描述符准备好数据时，I/O 复用函数把其中就绪的文件描述符返回给用户程序，用户程序只需要轮询I/O复用函数即可，I/O复用函数是阻塞式的，因此轮询并不会占用cpu资源
- 异步I/O
  - 以上四种I/O模型，最多只能实现异步形式的通知，而最重要的数据传输都是同步的，即数据传输都要由用户线程或进程亲自完成。
  - 异步I/O数据传输由内核接管，用户进程只需要发起I/O请求和等待完成通知即可

### linux I/O多路复用

- linux的IO多路复用，多路是指多个文件描述符，复用是指单线程或单进程可以同时监听多个文件描述符
  - I/O多路复用是linux的五种I/O模型中的一种，是为了解决在同一个用户进程内同时读写多个文件描述符的问题
  - 三种，select/pselect、poll、epoll
  - 通过 I/O 复用函数向内核注册一组文件描述符，当某个文件描述符准备好数据时，I/O 复用函数把其中就绪的文件描述符返回给用户程序，用户程序只需要轮询I/O复用函数即可。I/O复用函数是阻塞式的，因此循环调用并不会占用cpu资源。
  - I/O复用函数实际上是把文件描述符的状态检查交给内核去接管，用户进程只需要读写数据。
  - I/O多路复用通过超时时间来控制文件描述符的阻塞时间
  - select
    - 传给内核的文件描述符集用一个位图来表示，同时要传入一个最大文件描述符+1这个一个值，告诉内核传入的描述符数，内核常量FD_SETSIZE表示这个值的最大值（1024）。
    - select返回准备好的描述符数，并且会根据准备好的描述符集覆写用户传入的位图。等于说是select返回以后，用户还得自己去遍历传入的位图，下一次调用select的时候再重新设置位图。
    - 按事件类型将文件描述符集分为可读、可写和异常三个文件描述符集
    - select的变体pselect，调用的时候可以额外指定一个信号屏蔽字
  - poll
    - poll不像select一样为每个条件分别构造一个描述符集，而是采用一个数组，每个元素都是一个结构体，指定了文件描述符和事件类型。事件类型有两个，一个由用户写入，作为参数，一个由内核写入，作为返回。
    - poll突破了文件描述符1024上限的限制
  - epoll
    - epoll由linux 2.6版本引入
    - epoll有三个函数
      - epoll_create，创建epoll句柄（也是一个文件描述符）
      - epoll_ctl，注册文件描述符和事件
      - epoll_wait，等待事件发生
    - 相比select和poll，epoll解决了什么问题
      1. 解决了select文件描述符上限是1024这个问题
      2. 对于select和poll，内核通过轮询来检查文件描述符的状态，文件描述符越多，效率越低
      3. select和poll的每次调用是不相关的，每次调用都要重新构造参数，每次调用都会发生从用户态到内核态的内存拷贝
    - epoll的原理
      - epoll背后有一套数据结构在做支撑，因此不需要每次调用epoll_wait之前都重新注册文件描述符，减少了内存拷贝
      - epoll不是通过轮询来检查文件描述符的状态，而是给每个文件描述符注册一个回调函数，一旦有注册事件发生，就会调用回调函数把文件描述符加入一个就序列表，epoll_wait函数只是把这个就绪列表返回给用户，效率大大提升。
      - epoll有两种工作模式LT（默认）和ET
        - LT是如果一个文件描述符处于就绪状态，内核就会通知你操作，即使你每次都不做操作，内核还是每次都会通知你。LT同时支持阻塞式I/O和非阻塞式I/O
        - ET是内核只有在文件描述符发生变化的时候才会通知你，如果文件描述符就绪了，你没有做任何操作或者数据没读完，下次内核就不会继续通知你了，因为文件描述符的状态没有变。

### linux进程

- fork是一种copy-on-write机制
- 孤儿进程，父进程结束的进程，由init进程接管，父进程变为init进程
- 僵尸进程，进程技术执行，其他的资源都被回收，但是其进程控制块（task_struct）一直没被回收，处于这个状态的进程叫做僵尸进程。
  - 进程控制块通常是由父进程调用wait函数来回收，以获取子进程的返回码，运行状态等信息。
  - 解决办法，kill掉其父进程，僵尸进程会被init进程接管并回收。
- 进程组
  - 每个进程都属于一个进程组
  - 每个进程组有一个组长进程，组长进程的进程id和进程组一致
  - fork的子进程默认加入父进程的进程组
- 会话（session）
  - 会话和一个控制终端相关联，一个会话包含多个进程组，其中有一个是前台进程组，其他的是后台进程组
  - 会话首进程是控制进程，没有终端，会话首进程成为一个新进程组的组长
  - 用户在shell中启动的一个进程组称为一个作业
  - 只有前台作业能接受终端输入
- 孤儿进程组
  - 如果一个组的某个进程的父进程是同一会话中的另一个组的进程，那么这个组就不是孤儿进程组，否则它是孤儿进程组
  - 换个说法，一个组的所有进程的父进程要么是组内的一个进程，要么是会话外的一个进程。
  - 对于孤儿进程组，操作系统会给它们中的停止进程发送SIGHUP（挂断）信号。
- 守护进程
  - 守护进程是一种长期在系统后台运行的进程
  - 内核守护进程
    - ps命令输出的方括号中的进程是内核守护进程
    - 所有的内核进程由2号进程kthreadd创建，kthread也是一个内核进程。
    - 比如kswapd，负责内存换页
  - 用户守护进程
    - 由1号进程init创建，init是用户态进程
    - 比如inetd服务，负责侦听系统网络端口

### linux进程间通信（IPC）（10种）

- 信号，信号是一种软中断机制
  - 进程可以给一个信号注册一个处理函数，一旦接收到信号，就执行这个处理函数
  - 如何发信号
    - 用户按下某些终端按键，如ctrl+c
    - 用户使用某些特殊命令，如kill
    - 函数调用，如kill、raise、alarm
  - 作业控制信号
    - SIGINT，中断信号（ctrl+c）
    - SIGABRT，异常终止信号
    - SIGQUIT，退出（ctrl+\）
    - SIGTSTP，暂停（ctrl+z），可以忽视
    - SIGSTOP，暂停，不能忽视
    - SIGCONT，继续执行信号
    - SIGHUP信号，挂断会话
  - 其他信号
    - SIGTERM，请求退出
    - SIGKILL，强制退出
    - SIGIO，IO事件
- 管道
  - 只能在有公共祖先的进程间通信，比如父子进程
  - 调用pipe函数创建管道，返回两个文件描述符，对应管道的两端
  - 通常的做法是在父进程创建管道，然后fork子进程，这样子进程也拥有了这个管道。进程把自己不用的那端关掉。
  - 协同进程，现在有一个程序P，它从标准输入读，写到标准输出，如果有一个进程A，利用管道写P的标准输入，读P的标准输出，那么执行P的进程就是A的协同进程。
    - 具体实现，A fork 进程B，创建两个管道p1和p2，p1的方向是从A到B，p2的方向相反，然后在进程B中执行程序P，并将P的标准输入改为p1的读端，将P的标准输出改为p2的写端，这样就实现了A输出到P的标准输入，A从P的标准输入读，此时，B是A的协同进程。
- FIFO，又称命名管道
  - 和管道不同，FIFO可以在两个不相关的进程之间使用
  - FIFO创建在文件系统中，有路径名
- 三种XSI IPC（XSI是POSIX.1中的X/Open系统接口的简写，属于一种Unix规范）
  - 消息队列
    - 是内核中的一个链表，由消息队列标识符标识
    - 消息队列可以实现全双工通信
    - 消息队列最初的设计目的是提供全双工的高速通信，但随着后来很多新的IPC机制的提出，消息队列的性能优势已经不复存在，并且由于它存在的一些问题，新的程序里已经不推荐使用消息队列了。
    - 缺陷，没有引用计数
  - 信号量，是一个计数器，用来控制对临界资源的访问
    - 缺陷，信号量不是一个单个非负值，而是一个信号量值的集合；信号量的定义和初始化不是原子的；无端增加程序的复杂性
  - 共享内存
    - 共享内存允许多个进程共享一段内存空间，数据不需要来回拷贝，所以共享内存是一种最快的IPC
    - 共享内存段要先申请，然后连接到进程自己的内存地址空间
  - XSI IPC的统一缺陷
    - 它们在内核中是全局的，没有引用计数，不会自动回收，必须手动释放
    - XSI IPC的资源不是文件描述符的形式，而是各自专用的标识符
- posix信号量
  - 解决了XSI信号量的不少问题，性能更高，没有信号量集的设定，不需要手动管理
  - 推荐用这个
- 内存映射/存储映射（memory-mapped I/O mmap）
  - 把一个文件直接映射为一段内存地址，读写这段内存地址就相当于对这个文件I/O
  - 利用mmap实现
- socket
  - tcp、udp、unix域
- 记录锁
  - 对文件上锁，可以只对文件的一部分上锁
  - 三种操作：共享读、独占写、解锁
  - 记录锁只能用于多进程，不能用于多线程

### linux线程同步

- 线程基本操作
  - 创建，pthread_create
  - 终止，pthread_exit
  - 等待其他线程执行完毕，pthread_join
  - 请求取消另外一个线程，pthread_cancel，取消是一种非正常退出
  - 分离，pthread_detach，join操作不能等待分离线程
- 线程其他操作
  - 获取线程id
  - 注册线程清理函数
- 线程同步
  - 所有锁都可以设置阻塞时间
  - 互斥量mutex
  - 读写锁
  - 条件变量
    - 和互斥量配合使用
    - 使用步骤
      1. 用户设定一个条件
      2. 一个线程因等待条件成立而阻塞，`pthread_cond_wait()`
      3. 另外一个线程使条件成立，`pthread_cond_broadcast()`或`pthread_cond_signal()`
    - 条件变量分为两部分: 条件和变量。条件本身是由互斥量保护的，线程在改变条件状态前先要锁住互斥量。具体过程是这样的：线程进入wait前，由用户加锁mutex，线程进入wait后释放mutex，保证wait过程是原子操作；唤醒也一样，唤醒前先加锁，唤醒后解锁；
    - 条件变量类似于一个信号，线程本质上等待的是信号状态的改变
  - 自旋锁，不会让线程进入阻塞状态，而是进入忙等待状态，一直占用cpu资源
  - 屏障，各个线程在各自的某个位置设置一个屏障，先执行到屏障的线程停下来等待，等足够多的线程执行到屏障位置，大家再一起往下执行。pthread_join就是一种屏障，只不过只有一个线程在等待。
     
### linux内核

- linux内核主要负责
  - 内存管理
  - 进程和线程管理
  - 设备驱动
- 内核态和用户态
  - 内核态是内核程序运行的空间
  - 用户态是用户程序运行的空间
- 系统调用，内核态对用户态提供的访问接口
- 内存管理
  - 存储层次，CPU、缓存、内存、外存
  - 段页式内存管理
    - 把内存划分为大的段，在段内部分页
    - 一个地址的高位是段地址，地位是页地址
    - 段表相当于是页表的索引
  - 快表（TLB）和页表，块表是页表的缓存
  - numa，现代多核cpu通常是numa结构，每个核心都有自己的cache，可访问内存区域等，构成了每个核心的内存访问子系统
  - 进程的内存布局
    - 代码区
    - 数据区，分为两块，初始化的变量区和未初始化的变量区（bss区）
    - 常量区
    - 堆区
    - 栈区

## 网络

### 基础

- 网络体系结构
  - OSI七层：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层
    - OSI七层模型只是个参考模型，会话层和表示层只是理论上的层次
    - 会话层想要解决两个应用程序之间的会话管理问题
    - 表示层想要解决的是两个应用程序之间通信的语法语义问题，数据转换问题（编码解码，压缩和解压缩）
  - 五层：物理层，数据链路层，网络层，传输层，应用层
  - TCP/IP四层：网络接口层，网络层，传输层，应用层
- 数据链路层协议，CSMA/CD、PPP、PPPoE 
- 网络层协议，IP、ARP、RARP、OSPF、RIP、BGP
  - 路由协议，OSPF、RIP、BGP，内部网关协议IGP是一类协议
  - OSPF，是一种内部网关协议，开放最短路径优先协议，基于IP
  - RIP，是一种内部网关协议，距离矢量，基于UDP
  - BGP，边界网关协议，距离矢量，基于TCP
- 传输层协议，TCP、UDP
- 哪些基于UDP，RIP、DNS、DHCP
- http状态码
  - 1开头，信息性状态码，接受的请求正在处理
  - 2开头，成功
  - 3开头，重定向
  - 4开头，客户端错误
  - 5开头，服务端错误
- HTTP 1.0 为短连接，HTTP 1.1 支持长连接

### TCP三次握手四次挥手

- TCP报文结构
  - TCP报文=首部+数据部分，首部=20字节的定长部分+长度可变部分
  - 20字节的定长部分
    - 源端口+目的端口，4字节
    - 序号，4字节，报文序号（报文段第一个字节的序号）
    - 确认号，4字节，期望下次收到报文的序号
    - 数据偏移（首部长度），4bit，以4字节为单位，即首部长度=数据偏移值*4B，因此TCP首部最长60字节
    - 保留字段，6bit
    - 控制位，6bit
      - 紧急字段URG，当URG=1时，代表此报文段中有紧急数据，应尽快传送。
      - **确认字段ACK**，当ACK=1时，表示确认，且确认号有效；当ACK=0时，确认号字段无效。
      - 推送字段PSH，当PSH=1时，则报文段会被尽快地交付给目的方，不会对这样的报文段使用缓存策略。
      - 复位字段RST，当RST为1时，表明TCP连接中出现了严重的差错，必须释放连接，然后再重新建立连接。
      - **同步字段SYN**，当SYN=1时，表示发起一个连接请求。
      - **终止字段FIN**，用来释放连接。当FIN=1时，表明此报文段的发送端的数据已发送完成，并要求释放连接。
    - 窗口字段，2字节
    - 校验和字段，2字节，既校验首部又校验数据
    - 紧急指针字段，2字节
- 三次握手
  - 客户端状态变化，CLOSED,SYN-SENT,ESTABLISHED
  - 服务端状态变化，CLOSED,LISTEN,SYN-RCVD,ESTABLISHED
  - 过程
    1. 服务端从CLOSED变为LISTEN
    2. 客户端发送 SYN,seq=x,从CLOSED变为SYN-SENT，x是客户端设定的初始序号
    3. 服务端发送 SYN,ACK,seq=y,ack=x+1，从LISTEN变为SYN-RCVD
    4. 客户端发送 ACK,seq=x+1,ack=y+1,从SYN-SENT变为ESTABLISHED
    5. 服务端进入ESTABLISHED
  - 为什么不能两次握手
    - 两次握手的话，服务端只有两个状态，监听和建立连接，服务端很有可能因为一个延迟收到的连接请求单方面进入连接状态，浪费资源。比如客户端向服务端发起连接，客户端重试了一次，第二次成功建立了链接，等连接释放后，服务端才接收到第一次连接请求，当方面进入了连接状态，而客户端并没有进入连接，白白浪费了客户端资源。
    - 而客户端没有这个问题，因为客户端是主动发起连接的一方，只要客户端不想进入连接，不管他接收到什么数据，都不会影响客户端。
    - 加了第三次握手以后，重试的连接请求只能导致客户端进入SYN-RCVD状态，不会导致进入连接状态
- 四次挥手
  - 一方主动断开
    - 主动断开方A状态变化，ESTABLISHED,FIN-WAIT-1,FIN-WAIT-2,TIME-WAIT,CLOSED
    - 被动断开方B状态变化，ESTABLISHED,CLOSE-WAIT,LAST-ACK,CLOSED
    - A发送 FIN,seq=x，A从ESTABLISHED变为FIN-WAIT-1
    - B发送 ACK,ack=x+1，B从ESTABLISHED变为CLOSED-WAIT
    - A从FIN-WAIT-1变为FIN-WAIT-2
    - B发送 FIN,ACK,seq=y,ack=x+1，B从CLOSED-WAIT变为LAST-ACK
    - A发送ACK,seq=x+1,ack=y+1,A从FIN-WAIT-2变为TIME-WAIT（等待2MSL），最后变为CLOSED
    - B从LAST-ACK变为CLOSED
    - 为什么要四次挥手，让被动断开的一方把数据传输完毕
    - 主动断开一方为什么要等待2MSL，MSL是报文在网络中的最大生存时间，2MSL正好是报文一次往返的时间，这是为了等待所有报文在网络中消失
  - 两方同时断开
    - 双方同时向对方发送FIN，同时回复ACK，分别进行两次挥手，同时释放连接

### TCP如何保证可靠传输

- 滑动窗口+超时重传
  - 以字节为单位的，每个字节对应一个编号；（为了能重传和能判断字节序）
  - 发送窗口和接收窗口
    - 发送窗口中是允许发送的字节，发送窗口前部是已发送并得到确认的字节，发送窗口后部是不允许发送的字节；
    - 接收窗口中是允许接收的字节，接收窗口前部是已经收到并确认过的字节，接收窗口后部是不允许接收的字节；
    - 发送窗口是发送方的发送缓存的一部分；接收窗口是接收方的接收缓存的一部分；
  - 发送方和接收方
    - B会将自己的接收窗口大小发送给A，因此发送窗口一定不会大于接收窗口；
    - **发送方发送的数据需要得到接收方的确认**，如果发送方发送结束后迟迟没有收到确认，则会触发**超时重传**，直到收到确认为止；
    - 每一方都有自己的发送窗口和接收窗口；因此A的发送窗口和B的接收窗口是一对，反之是另外一对，**序号各是各的**；
- 校验和
- 选择确认（SACK）
  - 场景：接收方收到了一些数据，但另一些数据没有收到（或未按序到达），接收方希望发送方有选择地重传，而不是重传整个窗口的数据。
  - 建立TCP连接时，在TCP首部加上"允许SACK"的选项，然后在TCP报文中加入需要重传的字节段的边界序号；

### TCP流量控制

- 流量控制是指让发送方发送不要太快，让接收方来得及接收；
- 利用滑动窗口控制流量；当接收方感觉发送速率过快时，减小接收窗口，并将新的窗口值发送给发送方；
- 零窗口时（接收窗口降为0时），发送方启动一个计时器，每隔一段时间发送一个探测报文，去获得当前最新的窗口值；防止接收方发出的窗口值更新报文滞留在网络中。

### TCP拥塞控制

- 拥塞控制的目的是防止大量的报文进入网络中，把负载控制在网络可承受的范围内；
- 四种方法：（1）慢开始，（2）拥塞避免，（3）快重传，（4）快恢复
  - **拥塞窗口**，发送方根据网络状态自己计算出的一个窗口；可以理解为发送窗口=min（拥塞窗口，接收窗口）
  - 发送方通过是否发生确认超时来判断是否发生了拥塞，以此来调整拥塞窗口的大小；
  - 慢开始：
    - 发送方逐渐增加拥塞窗口，而不是一下子增大拥塞窗口；
    - 发送方每收到一个确认，就把拥塞窗口增大一些；（增大速度不是线性的，是乘法增大），因为拥塞窗口增大后，发送能发出更多的报文，能收到更多的确认，拥塞窗口会增加得越来越快）
  - 拥塞避免：
    - 把拥塞窗口的**乘法增大改为加法增大**
    - 慢开始和拥塞避免这两个过程之间有一个**门限值ssthresh**，拥塞窗口过了这个门限值以后切换拥塞控制算法；
    - **发生超时时，把门限值设为当前拥塞窗口的一半，重新开始执行慢开始**。
  - 快重传
    - 快重传是为了避免发送方误以为网络发生了拥塞从而降低传输效率；
    - 接收方在未正确收到一个数据时，应立即重复确认上一个正确收到的数据，发送方一旦收到连续三个重复确认，就马上重传数据，而不会进入超时等待；
  - 快恢复
    - 发送方现在知道了只是**丢失了个别数据**，因此重传的时候不执行慢开始，把发送窗口增大到门限值后**直接进入拥塞避免**算法；

### HTTP



### unix套接字

- 概念
  - 进程，是一个通信实体
  - ip:port，是一种通信地址资源
  - unix套接字，是对一个通信端点的抽象
  - 套接字类型（可以看作是对传输特性的描述）
    - SOCK_DGRAM，固定长度、无连接、不可靠的报文传输
    - SOCK_STREAM，面向连接、有序、可靠的字节流传输
    - SOCK_RAW，IP协议的数据报接口
    - SOCK_SEQPACKET，固定长度、面向连接、有序、可靠的报文传输
  - 域类型
    - AF_INET，IPv4域
    - AF_INET6，IPv6域
    - AF_UNIX，unix域
    - AF_UNSPEC，未指定
  - **套接字和域的组合决定了协议**，一个组合可以对应多个协议，在IPv4域中，SOCK_STREAM默认对应TCP协议，SOCK_DGRAM默认对应UDP协议
- 操作
  - socket，创建一个套接字
  - bind，绑定一个ip:port
  - 服务端
    - listen，监听请求，监听请求的套接字称为原始套接字
    - accept，获得一个连接请求并建立连接，每个连接对应一个新套接字，它们的地址和原始套接字相同
  - 客户端
    - connect，和服务端建立连接
  - close，关闭套接字
- **一个ip:port可以建立多个tcp连接吗？**
  - 连接是通过套接字建立的，**一般情况下，一个ip:port只能绑定到一个套接字上**，如果ip:port被占用，又试图去用另外一个套接字用这个地址通信，就会出现端口冲突。
  - 对于服务端，原始套接字负责监听，每建立一个连接，就创建一个新套接字负责数据传输，原始套接字和新套接字共用一个地址。因此，**对于服务端，一个ip:port可以通过原始套接字建立多个tcp连接**。或者说，只能有一个套接字监听一个ip:port，但是可以和多个客户端建立连接。
  - 对于客户端，没有原始套接字的概念，一个套接字只能建立一个tcp连接，因而，**对于客户端，一个ip:port只能建立一个tcp连接**。

### 如何实现接口的幂等性

- 接口的幂等性是指多次请求同一个资源和只请求一次产生同样的效果
- 接口需要满足幂等的原因是很多操作我们只希望发生一次，比如付款、创建订单等等
- 读操作天然具备幂等性
- 如何实现写幂等性
  - 插入和删除
    - 在数据库层面，使用唯一key标识一个资源，避免重复插入同一个key
  - 更新
    - 为每个资源记录一个状态，根据状态判断是否能执行操作
    - 使用乐观锁或者悲观锁防止操作时出现的幻读问题
  - 高并发下可以使用分布式锁防止请求直接落到数据库上

## 分布式

### 分布式概念
- CAP原理，一致性、可用性、分区容错性三者不可兼得
- BASE原理，是在满足分区容错性的前提下，在一致性和可用性之间做的权衡，是指分布式系统可以同时满足基本可用性、软状态和最终一致性。
- 脑裂问题，分布式系统发生分区错误后，各分区选举出各自新的master导致分布式系统中存在多个master的情况

### 分布式锁

- 分布式锁要解决以下问题
  1. 锁失效的问题，包括集群脑裂、锁到期、锁丢失（master节点挂掉而数据同步还没完成）
  2. 非阻塞问题，获取不到锁要能返回失败
  3. 可重入问题，同一个实例，要能反复获取同一个锁
- 基于redis实现分布式锁
- 基于zookeeper实现分布式锁
- 基于数据库实现分布式锁

### 分布式id

- 为一个资源生成一个全局的唯一id
- 方法
  - UUID、hash（不推荐）
    - 优点，可以本地生成，无网络消耗
    - 缺点，无序，无法建立索引
  - 利用数据库自增id
    - 缺点，存在数据库单点问题，数据库访问压力大
  - 从数据库批量获取自增id
  - 利用redis的incr命令实现id的原子性自增
    - 优点是快，缺点是贵
  - 雪花算法（snowflake）
    - 优点，可以本地生成，不需要一个中心化的分布式id服务
    - 原理其实就是通过一些特定标识的拼接，让生成的id不重复的同时还能做到有序

## mysql

### 索引

- 什么是索引
  - 索引是一种能实现对表中某一列或多列的值快速查找的数据结构，常见的是 B+树
  - B+树是一种多叉搜索树，叶节点是数据节点，存放着指向行数据的指针，叶节点之间顺序链接
  - 没有索引的时候，数据的物理存储是按插入顺序存储的，查找数据时要逐行查找
- 索引的优缺点
  - 优点：
    - 加快查询速度
    - 缩小锁的范围（比如 gap lock 和 next key lock）
  - 缺点：维护索引要耗费时间和空间，会降低写入速度
- mysql 索引分类
  - 普通索引、唯一索引、主键索引
    - 普通索引允许重复值和空值
    - 唯一索引不允许重复值，但允许空值
    - 主键索引既不允许重复值，又不允许空值
  - 单列索引和组合索引
    - 组合索引是在多列上构建的索引，查询条件（1）包含组合索引列的前缀并且（2）用 and 连接时才会触发组合索引
  - 全文索引
    - 可以在列上进行全文搜索
- 怎么判断要不要加索引
  - 加
    - 在频繁进行条件判断、分组、排序的列上创建索引
    - 多读少写或者对读操作耗时要求高时加索引
  - 不加
    - 写多读少时不要加所索引
    - 不做条件判断的列不要加索引
    - 数据大量重复时也不应该加索引
- 索引命中和失效
  - 不符合左前缀原则会导致组合索引失效
  - where 条件不用 and 连接会导致组合索引失效
  - 在索引列上做计算、函数调用、不等于比较会导致索引失效
  - 可以用 explain 语句查看是否命中索引，explain 语句是用来查看 sql 执行计划的
- 索引实现上分为聚集索引和非聚集索引
  - 一个表只能有一个聚集索引，之所以叫聚集索引，是因为数据的物理存储顺序就是按聚集索引的排序存储的，也是因为这个原因，一个表只能有一个聚集索引。InnoDB 的聚集索引叶节点存储完整的数据记录。
  - 其他索引都属于非聚集索引，非聚集索引也叫二级索引或者辅助索引，非聚集索引有两种情况
    1. 数据节点不是直接指向数据记录，而是保存一个聚集索引的 key，每次对非聚集索引的查找都要到聚集索引上查一次数据，这叫“**回表**”。（mysql 的 InnoDB 引擎）
    2. 叶节点直接指向对应的数据块。（mysql 的 MyISAM）
  - mysql InnoDB 引擎一定会构建一个聚集索引，默认会将主键索引作为聚集索引，如果没有主键索引，会将第一个没有空值的唯一索引作为聚集索引，否则会在一个隐藏的 ROWID 上构建聚集索引，ROWID 是行的唯一标识
  - 组合索引是以多个列的组合作为 key，例如"(2,3)"

### 2kw 是数据量上限这个说法从何而来

- 我们通常认为 B+树超过三层性能会下降
- mysql innodb 一个 B+树节点 16KB，可用空间 15KB
- 假设 key 是 bigint 类型（8B），key 加指针（4B）一共 12B
- 因此第二层有 1280 个节点，第三层有 1280\*1280 个节点
- 假设单行数据 1KB，那三层 B+树支持的数据量是 1280\*1280\*15KB/1KB=24576000，也就是 2kw+
- 2kw 只是个参考值，单行数据量如果不是 1KB，数据量上限就不是 2kw 了。机器的硬件配置也会影响 mysql 的性能，比如用 ssd 代替机械硬盘、使用大内存都会提高 mysql 的性能。

### 事务

- ACID 特性
  - 原子性、一致性、隔离性、持久性
- InnoDB 如何实现事务的 ACID 特性
  - 原子性，通过 undo log 回滚
  - 一致性
  - 隔离性
    - 通过锁保证隔离性，事务在修改数据之前先对数据上锁。锁按照粒度分为表锁和行锁。
    - 使用 MVCC（多版本并发控制）解决读写阻塞的问题，提高读性能。
      - 快照读，利用快照读可以实现可重复读
  - 持久性，数据落盘之前先要放到 buffer pool，buffer pool 的数据会定期刷到磁盘上去，写入 buffer pool 之前先写到 redo log 中，防止保证数据不会因宕机丢失

### InnoDB 的锁

- InnoDB 的锁按粒度分为
  - 行锁和表锁
  - 意向锁和非意向锁
- 按并发控制分为共享锁和排他锁
  - 共享锁：可以对数据上多个共享锁，但不能同时上共享锁和排他锁（有点像并发编程的读锁）
  - 排他锁：只能对数据上一个排他锁（有点像并发编程的写锁）
- 意向锁只能是表级，非意向锁可以是表级的也可以是行级的，因此一共有 6 种组合
  - 表级的排他锁
  - 表级的共享锁
  - 行级的排他锁
  - 行级的共享锁
  - 表级的排他意向锁
  - 表级的共享意向锁
- **申请行级锁之前要先申请表级的意向锁**（意向锁相当于是行锁在表这个级别的代表）
- 表级锁互斥性（X-排他锁，S-共享锁，I-意向锁）
  ||X|IX|S|IS|
  |---|---|---|---|---|
  |X|×|×|×|×|
  |IX|×|√|×|√|
  |S|×|×|√|√|
  |IS|×|√|√|√|
- 行锁有三种
  - record lock，单行锁
  - gap lock，锁住两个索引值之间的空隙（空隙是指还没有插入值），目的是为了防止幻读，注意，如果没有命中索引，gap 锁会锁全表。
  - next-key lock，以上两种锁的结合，也是为了防止幻读。

### InnoDB MVCC

- MVCC 的全称是多版本并发控制，目的是提高数据库的并发性能，实现读-写冲突不加锁
- 数据库并发场景
  - 读-读：不需要并发控制
  - 读-写：存在脏读、不可重复读、幻读问题
  - 写-写：存在写入脏数据问题
- InnoDB 的读分为快照读和当前读
  - 当前读，读当前最新的数据，只能通过加锁实现当前读
    - select for update、update、insert、dalete 属于当前读
  - 快照读，读一个历史版本，MVCC 利用快照读实现读-写并发不加锁
    - select 属于快照读
- MVCC 通过数据记录的三个隐含字段、undo log、read view 实现读-写不加锁
  - 三个隐藏字段：行 id、上版本指针、最后一个修改数据的事务 id
  - 各版本会形成一条版本链
  - read view，快照，会把和本次读取时的事务 id 和快照作比较，保持快照的一致

### 其他

mysql 的主从同步，利用主服务的 binlog 和从服务的 relay log 实现

### 悲观锁和乐观锁

- repeatable read 隔离级别及以下需要使用悲观锁和乐观锁
- 悲观锁和乐观锁是用户层面的概念，不是 mysql 内部的概念，目的是为了解决写-写冲突
- 悲观锁是指对数据并发持悲观态度，认为一定会冲突，悲观锁是在操作数据之前对数据上锁
  - 一般使用数据库本身的锁作为悲观锁
  - 哪些操作可以上锁
    - select for update
    - update、insert、delete
- 乐观锁是指对数据并发持乐观态度，认为不一定会冲突，乐观锁是在写入数据时才对数据上锁
  - 乐观锁一般要配合一个额外的表字段，比如时间戳、版本号等，事务开启后，先查询版本，update 时查询版本并更新版本，由于 update 是当前读，因此 RR 隔离级别乐观锁是有效的

### 优化

- 表优化
  - 建索引、去掉不该有的索引
  - 拆分表，拆出频率低的字段，冗余多的字段
  - 分表分库
  - 优化字段类型
    - 用整型代替字符串类型
- SQL 优化
  - 不用 select \*，减少“回表”，减少网络传输
  - 修改不命中索引的写法
    - explain 命令查看 sql 的执行计划，可以看到是否命中索引
    - 不等于比较，字段上进行函数调用，对字段做计算，使用like匹配字符串
    - 组合索引不符合最左前缀原则，使用or连接条件
  - 用联结查询代替子查询
  - 用命中索引的范围查询代替偏移量非常大的limit语句
  - 利用慢查询日志查看执行的比较慢的语句

### log

- bin log，记录所有对数据的修改操作
- redo log，用于数据的持久化，防止数据因宕机丢失
- undo log，用于回滚数据

## redis

### redis的功能

- redis 是什么
  - redis 是一种内存型 kv 数据库，性能高，它的高性能来源于内存存储和 kv 型存储，数据结构简单
  - 通常用来做缓存
- redis 的 5 种主要数据类型
  - string，`set key value`, `get key`,`mget`, `mset`
  - hash，`hset hashkey field value`,`hget hashkey field`, `hmset`, `hmget`, `hgetall`
  - list，`lpush key element1 element2`，插入到列表头部
  - set，无序，查找时间O(1)
  - 有序集合，查找时间O(1)，用户给每个key指定一个分数，靠分数排序
- redis的单线程模型
  - redis的命令执行是单线程的，不存在并发问题
  - redis6.0对网络io引入了多线程，但是核心的命令执行仍然是单线程的
  - redis利用队列把网络连接和数据处理做了解耦
- redis为什么高性能
  - 高性能来自内存存储和key-value数据结构
  - 高并发来自基于epoll的I/O多路复用
- **redis中的原子性**
  - redis中经常会提到“原子性”这个词，redis中的原子性是指两条命令之间不会插入其他命令，可以保证严格的前后相邻顺序，但是并不保证全部执行成功，也不会回滚，会出现指令全部执行完毕后，一部分执行成功，另一部分失败
  - 哪些功能能保证原子性
    - 事务
    - lua脚本
  - 哪些保证不了
    - pipeline，pipeline是客户端的行为，对redis是透明的
- redis的事务
  - redis的事务实际上就是一组顺序执行的命令集合。
  - redis保证事务执行的原子性。
  - 由于redis的单线程模型，redis不存在命令的并发，也不存在隔离级别。
- redis的watch命令
  - 和事务配合使用
  - watch命令用来监控一个或多个指定的key，如果在事务执行之前，被监控的key被修改，则事务取消执行。
  - 类似一种乐观锁机制，防止多个客户端之间出现并发冲突。
- redis的setnx命令
  - key不存在时才会写入，写入成功返回0，写入失败返回1

### redis缓存击穿、穿透、雪崩

1. 高并发场景下，大量请求查询一个在数据库中存在但是在缓存中不存在的值，导致大量请求直接落到数据库的问题
    - 限流，例如，对于一个值，只允许一个请求访问数据库，可以为这个key设置分布式锁
2. 高并发场景下，大量请求查询一个在数据库和缓存中都不存在的值，导致大量请求不停地落到数据库的问题
    - 允许存储null值
3. 高并发下场景下，缓存中很多值在同一时间过期，导致大量请求直接落到数据库的问题
    - 设置随机过期时间

### 利用redis实现分布式锁

- 方案1：
  - setnx + expire + lua/事务，lua/事务保证setnx+expire成为原子操作（老办法）
  - set ... ex ... nx，set命令自带nx和ex，单条命令实现setnx + expire的功能（新办法）
  - 问题1，实例A上锁，实例A执行期间锁超时被释放了，实例B趁机获得了锁，A执行完毕后把B的锁给释放了。问题2，实例A上锁，master节点挂了，锁还没同步到slave节点上，B实例趁机获得了锁，A执行完毕后把B的锁给释放了。
    - value设置为A的标识，释放锁时先查标识，标识对上才能释放
    - 先查再删需要保证原子性，解决办法，使用lua/事务
- 方案2：redlock算法，redis官方提出的分布式锁算法，在redis集群部署的情况下可以保证高稳定性。
  - 假设redis有n个节点，该算法认为，只要超过一般的节点加锁成功，就认为加锁成功，如果加锁的时间超过了超时时间，认为加锁失败。解锁时对全部节点解锁。

### redis的缓存淘汰策略

- redis中分为两个数据字典，一个字典存所有的key-value，一个字典存key和对应的expire（称为expire字典，只有配置了过期时间的key才会在这里面）
- redis的缓存淘汰策略
  1. 不淘汰任何键，直接返回错误
  2. 在所有key中随机删除
  3. 在所有key中使用LRU算法删除（最近最少使用）
  4. 在所有key中使用LFU算法删除（使用频率最低）
  5. 在expire字典中随机删除key
  6. 在expire字典中删除马上快过期的
  7. 在expire字典中使用LRU算法删除
  8. 在expire字典中使用LFU算法删除
- redis的key过期策略
  - 惰性删除，当客户访问key的时候判断key是否过期，过期就删除
  - 定期删除，在expire字典中随机采样，取20个key，删掉里面过期的key，如果过期key占比超过1/4，就重复这个过程

### 如何保证缓存和数据库的一致性

- 分布式系统要保证分区容错性和可用性，就没办法保证数据的强一致性，最多保证最终一致性，甚至是弱一致性。
- 方案1：写入命中缓存时，既更新数据库，又更新缓存。
  - 问题1：其中一个操作失败导致数据不一致
  - 问题2：不管是先写缓存还是后写缓存，都会存在写并发问题，例如“A写缓存X=1，B写缓存X=2，B写数据库X=2，A写数据库X=1”，造成了数据不一致。
- 方案2：写入时删除缓存，写数据库。由读请求写缓存。
  - 问题1：其中一个操作失败导致数据不一致
  - 问题2：不存在写并发问题，但存在读写并发问题。
- 方案1和方案2都会遇到操作失败和并发问题，解决方案
  - 对于并发问题，使用分布式锁
  - 对于操作失败问题
    1. 重试，缺陷是会占用更多资源，并且即使是无限重试也不一定100%成功
    2. 异步重试，利用消息队列重试，缺陷是会提高系统复杂度，要解决消息队列的失败问题。
    3. 利用数据库的变更日志更新缓存（例如mysql的binlog）
- 从整体复杂度来讲，方案2更好一些，对于方案2，还可以采用写DB后延迟一段时间删除缓存的策略，尽量让缓存不会被写回旧数据
- 此外，数据不一致还可能由redis和数据库内部数据不同步导致。
- 总之，实现数据的强一致性是不可能的，最终一致性也不能百分百保证，因此，最后，引入手动补偿机制，手动修复极端情况下的不一致数据

## MQ

### MQ的用途

- 削峰
- 解耦
- 异步

### kafka的特点

- 高吞吐量
- 消息可持久性存储
- 分布式，支持横向扩展
- 稳定性低，容易丢数据，容易出现数据重复

### kafka原理

- kafka是pull模型，不是push模型，消费者要主动拉取数据。
- kafka分为queue模式和topic模式
  - queue模式，消息是按顺序消费的，消费者主动拉取消息，每个消息只能被一个消费者消费，并且只能消费一次。
  - topic模式，发布订阅模式，一个topic分多个partition，消费者组成消费者组，topic由消费者组订阅。
    - 同一个topic中，同一个partition内的消息是有序的，不同paitition之间的消息是无序的。
    - 无论消不消费，消息都不会被删除，直到过期。 
    - 一个消费者组订阅一个topic，消息被均衡地送给每个消费者，分配给各消费者的partition互不相同（不存在两个消费者消费同一个partition的情况）。消费者数量大于partition数量时，会有消费者空闲。
    - 生产者和消费者都可以指定固定的订阅分区
    - rebalance，重平衡，消费者组内消费者数量发生变化时，分区会重新分配，这叫rebalance，消费者定期向partition发送心跳来证明自己存活。
    - 一个topic可以由多个消费者组订阅，并且这些消费者组消费到的消息是完全相同的。如果想让不同的消费者消费同一个partition，就要把它们分到不同的组中。为了支持同一个消息能被多个消费者消费，kafka会记录partition中不同消费者各自的消费位置。
    - 每个partition又有多个副本，其中一个是leader副本，其余的是follower副本，leader负责收发消息，follower是备份，leader和follower分布在不同的节点上。
    - kafka的节点称为broker
- 生产者同步发送和异步发送模式
  - `producer.type`参数指定了生产者是同步发送还是异步发送，值为asnyc时为异步发送，值为sync时为同步发送。用户调用`send()`方法时，kafka会根据producer.type参数决定消息的发送方式，如果是同步发送，就会直接发送消息，如果是异步发送，会先把消息放入一个本地缓存，然后启动一个发送线程，当缓存中的消息满足一定条件时，发送线程批量发送消息。
  - **不管同步还是异步模式，消息都是按序发送的，只有发送失败时，才可能破坏发送消息的顺序。**
  - send函数本身的调用方式是异步调用，也就是说，不管发送模式是同步还是异步，send都会立即返回。
  - `send().get()`只是将函数的调用方式从异步改成同步，并不会改变producer的发送模式。
- kafka如何实现三种消息传递语义
  - at most once，最多一次，消息不会重复，但有可能丢 
    - ack=0就是at most once
  - at least once，至少一次，消息不会丢，但有可能重复
      - ack=1或者ack=all，配合retries
  - exaclty once，不多不少正好一次
    - ack=all配合retries，保证不丢数据
    - 启用kafka的幂等配置，`enable.idempotence`，保证重试不会导致消息重复
    - 消费者处理完消息之后再手动提交offset，保证消费
- 消费者自动、同步、异步提交
  - 消费者可以配置自动提交offset（`auto.commit.enable`参数），自动提交和消费消息是异步的，消费者会定期向kafka提交offset。自动提交可能会造成消息丢失，即提交成功但是消费失败
  - 手动同步提交，除了会阻塞，没什么问题
  - 手动异步提交，异步提交不会发生阻塞，但是kafka没给异步提交提供重试机制（防止重试导致旧的提交覆盖新的提交）。（但是提交失败本身也会导致重复消费）
- kafka事务
  - 事务场景
    - 发送多条消息到一个topic
    - 发送到多个topic、多个partition（典型的分布式事务）
    - 消费-处理-发送
  - 保证多个消息、多个操作的原子性，即同时成功，同时失败，失败会回滚。

### kafka如何保证顺序消费

- topic端，让生产者和消费者指定同一个partition，并且保证分区有足够多的副本，防止partition挂掉。
- 生产端，单线程发送消息
  - 消息丢失会破坏消息顺序，所以要配置ack=1或ack=all并配置重试
  - 同时发出多次消息时可能会破坏消息的顺序性（异步发送的一批数据算一次），因此，要将`max.in.flight.requests.per.connection`参数设置为1（这个参数规定了生产者能同时发送多少条未经确认的消息），还要配置ack=1或ack=all能让broker确认消息。
- 消费端，单线程消费消息

### kafka如何防止消息丢失

- 生产者丢消息
  - kafka客户端支持异步发送消息，生产者丢失消息会发生在这个过程中，可能会由于网络原因或者数据太大等原因发送失败
  - 解决方法
    1. 配置retries，消息发送失败就重试
    2. 给发送方法加回调函数，消息发送失败时进行特殊处理（例如重试、记录日志并根据日志异步重试）
- broker丢消息
  - leader分区每收到一条消息都要同步到follower，如果数据还没落盘或者没等同步完leader就挂了，某一个follower成为了新的leader，就会导致消息丢失。
  - 解决办法，利用ack机制解决
    - ack机制是指kafka接收到消息后会向生产者发送确认，**ack参数影响了kafka的消息持久性**，ack参数有三种（`request.required.acks`参数）
      - ack = 0， 生产者不会等待broker发送ack，这种情况无法保证不丢数据。（生产者的retries参数这时也是失效的）
      - ack = 1，leader分区接收到数据后，向生产者返回ack，如果消息没有同步到follower中，就会导致数据丢失。（kafka默认的是ack=1）
      - ack = all，等leader向所有follower同步完数据，才会返回ack。
    - 可以利用ack=all配合retries参数让生产者失败重试，保证数据不丢失。（`message.send.max.retries`参数用来设置发送端重试次数）
- 消费者丢消息
  - 消费者可以配置自动提交offset（`auto.commit.enable`参数），自动提交和消费消息是异步的，消费者会定期向kafka提交offset，如果offset已经提交，而消息消费失败，就会丢失消息
  - 解决办法，将自动提交offset改为手动提交，消息消费完成后再提交offset

### kafka如何防止消息重复

- 消息重复的情况
  - 生产者失败重试导致的消息重复
  -  消费者未提交offset导致的消息重复
      - 消息处理完成，消费者突然挂了，未能成功提交offset
      - 消息正在处理，partition发生了重平衡
  - 上游业务发送了重复的消息
- 解决办法
  - 对于第一种情况，启用kafka幂等配置，重试不会导致消息重复
  - 对于后两种情况，需要在业务层面实现接口的幂等性

## 系统设计

### 高并发、高性能、高可用

- 数据库一主多从，读写分离
  - 降低单台数据库负载
  - 避免写请求阻塞
- 提高系统稳定性（高可用）
  - 超时+重试
  - 限流
  - 降级
  - 异步
  - 缓存
  - 冗余（分布式部署，做集群，读写分离）
- qps，每秒请求数
- 并发=qps*平响

### restful api

- 把接口视为资源
- 用HTTP方法表示操作，GET、POST、PUT、DELETE，读取、新增、修改、删除
- 接口命名（命名中只包含资源，不能包含操作）

### 设计模式

- 单例模式，静态全局变量，私有构造函数，静态方法获取全局变量
  - 懒汉式，获取时初始化单例（存在线程安全问题）
  - 饿汉式，直接初始化单例
- 工厂模式
  - 简单工厂，根据参数返回特性对象
  - 抽象工厂，根据参数返回特定工厂
- 模板模式

### 场景题

略

## elastic search

- elastic search，弹性搜索，是一种分布式全文检索搜索引擎，全文检索功能基于Lucene（一个全文检索库）实现
- 全文检索，获取文档、切词、建倒排索引、查询、算分、召回
- es概念
  - 索引（index），相当于数据库
  - 类型（type），索引内部的逻辑分区，相当于数据库的表
  - 文档（document），文档是Lucene索引和搜索的基本单位，用json表示，相当于数据库的行
  - 字段（field），字段类型，字符串、整型、浮点型、布尔、二进制、时间、地理位置
  - 映射（mapping），映射定义了文档和字段的存储和索引方式，相当于数据库的表定义
    - 映射中可以定义type的元信息
    - 字段的元信息，包括字段类型、是否被索引、是否切词（不切词就是精确匹配）、切词器的类型
- 所有数据都能纳入索引
- 分片，es将一个索引分成多部份存储在多个节点上，每个部分成为一个分片。分片有多个副本，默认是双副本
- es使用restful api访问
- 查询结果根据默认根据相关性排序（_score），也可以指定按照某个字段排序
- **缺陷：不支持事务，耗费资源大**

## MongoDB

- 文档型分布式nosql数据库
- 热数据内存存储
- 比redis便宜，比mysql贵

## gin

- 主要概念
  - engine、handelr、router、conetxt、bind
- engine，是一个gin框架的全局实例，RouterGroup（定义了一个路由组，保存了该路由组的中间件和请求路径）、Trees（包含所有路由前缀树，查找路由，根据请求方法对树分类。并保存了每个路由对应的handler）
- context
  -是handler会传入一个gin context指针，一般命名为c
  - gin context实现了go的Context接口的四个函数，Done、Value、Deadline、Err，所以gin context也是一个context
  - gin context定义了一个key map，调用Value时首先去这个key map里面找，还带了一个读写锁用来保护这个key map，可以并发读写key map（go原生的valuectx不能并发，只能被一个goroutine操作，除非你自己给它上锁）
  - gin context定义了一个copy函数，启动新goroutine的时候可以拷贝
- request body和一个struct绑定以后会被清空，不能再次使用
  - 多次绑定可以使用ShouldBindBodyWith
- http server
  - 不要直接调用r.Run()，而是把r作为handler传入一个http.Server变量，调用http.Server的ListenAndServe()启动服务
  - 如果想自定义端口、超时等配置，给http.Server的对应成员赋值即可
  - 利用goroutine、信号、和http.Server的Shutdown()函数实现优雅退出
- gin handler（gin 中间件）
  - 一个gin handler就是一个处理函数，gin在请求处理的某个阶段调用这些handler，handler相当于是请求处理的钩子函数
  - handler负责打日志、鉴权、异常恢复等工作
  - （请求处理函数本身其实也是个handler）
  - handler分局部和全局的，局部handler对一个路由生效，全局handler对所有路由生效
  - handler可以在请求处理函数之前执行，也可以在请求处理函数之后执行
  - 在handler中调用next方法的作用是，调用next之前的代码在请求处理之前执行（前置），调用next之后的代码在请求处理之后执行（后置）。（这个不难理解，next的作用是执行其他handler，如果其中一个handler中没有调用next，那它整个是前置的，如果其中一个handler也调了next，就继续递归处理其他handler，最后一个handler是请求处理函数，请求处理函数执行完毕后，递归调用返回时，触发所有handler的后置部分）

## docker和k8s

- docker是一种容器技术，容器是一种轻量的虚拟化技术，其最大的好处是能让程序在不同平台上有一致的执行环境。
- docker可以用来创建一个容器。容器是根据配置文件将程序依赖的库等各种环境打包在一起，形成一个独立的运行环境。
- docker基于 Linux 内核的 cgroup，namespace，以及 Union FS 技术实现了容器之间的隔离
- docker的三个概念，镜像、容器、仓库
  - 镜像是基于UnionFS实现的个特殊的文件系统，里面包含了程序所需要的所有环境。
  - 容器是镜像运行的实体（这个有点像进程和程序的关系），容器的本质就是进程，他有自己的namespace，只能访问自己的命名空间里的文件，靠这个实现了文件系统之间的隔离
  - 仓库是一个用来分发镜像的系统。
- k8s
  - 容器编排服务
  - 通常称作k8s集群，主要是管理容器生命周期，对服务做扩缩容
