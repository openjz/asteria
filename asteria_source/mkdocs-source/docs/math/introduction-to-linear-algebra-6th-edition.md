---
title: "《线性代数（第6版）》学习笔记"
date: 2025-12-12T10:07:00+08:00
draft: false

tags: ["数学"]
categories: ["数学"]
---

《线性代数（第6版）》由Gilbert Strang（吉尔伯特·斯特朗）编写，是线性代数领域的经典教材。

这个笔记的内容来自MIT的线性代数课程以及《线性代数（第6版）》这本教材。

## 线性方程组的几何解释

**线性组合**

$$
\begin{cases}
2x-y=0 \\
-x+2y=3
\end{cases}
$$

我们可以将其表示为矩阵形式：

$$
\begin{bmatrix}
2 & -1 \\
-1 & 2 \\
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
3 \\
\end{bmatrix}
$$

我们可以将其记为 $Ax=b$。

站在行的角度来看，这个方程组中的每个方程都可以确定一条直线，方程组是在求两条直线的交点。

站在列的角度来看，它的列视图可以表示为：

$$
x\begin{bmatrix}
2 \\
-1 \\
\end{bmatrix}
+
y\begin{bmatrix}
-1 \\
2 \\
\end{bmatrix}
=
\begin{bmatrix}
0 \\
3 \\
\end{bmatrix}
$$

这实际上是两个列向量的**线性组合（Linear Combination）**。

考虑以下三元线性方程组

$$
\begin{cases}
2x-y=0 \\
-x+2y-z=-1 \\
-3y+4z=4
\end{cases}
$$

和二元线性方程组同理，站在行的角度，每个方程都可以确定一个平面，方程组是在求三个平面的交点。站在列的角度，可以将方程组表示为 $Ax = b$。

**奇异/不可逆**

站在列的角度，考虑这样一个问题，对于 $Ax = b$，是不是对于任意的 $b$，都存在解 $x$ 呢？换句话说，列向量的线性组合能否覆盖整个三维空间？

假设三个列向量处于同一个平面内，答案就是否定的，一个平面外的向量必然不能被这三个列向量的线性组合表示出来。这种情况，我们称之为**奇异（Singular）**或矩阵**不可逆（Invertible）**。（原因在于这三个列向量不是完全相互独立的）

**矩阵乘向量**

两种方法：

1. 将矩阵的每一行与向量做点积
2. 将矩阵的列向量与向量的每个分量做线性组合

## 矩阵消元（Elimination）

### 消元和回代

矩阵消元是让每个方程组消去一个未知数，使系数矩阵成为一个上三角矩阵 $U$（又叫高斯消元法）。

考虑以下线性方程组：

$$
\begin{cases}
x + 2y +  z = 2 \\
3x + 8y +  z = 12 \\
0x + 4y +  z = 2
\end{cases}
$$

我们可以将其表示为矩阵相乘形式 $Ax = b$

消元法要将系数矩阵 $A$ 变为上三角矩阵 $U$：

$$
\begin{bmatrix}
1 & 2 & 1 \\
3 & 8 & 1 \\
0 & 4 & 1 \\
\end{bmatrix}
\to
\begin{bmatrix}
1 & 2 & 1 \\
0 & 2 & -2 \\
0 & 0 & 5 \\
\end{bmatrix}
$$

对角线上的元素称为**主元（Pivot）**，主元不能是0。

如果主元的数量不够，少于未知数的数量，意味着消元法失效了。

**回代（Back Substitution）**

将线性方程组等号右侧的 $b$ 加入到系数矩阵中，新的矩阵称为增广矩阵（Augmented Matrix），对增广矩阵做消元法，最右侧一列会同步变化，我们将新的一列记为 $c$：

$$
\begin{bmatrix}
1 & 2 & 1 & 2\\
3 & 8 & 1 & 12\\
0 & 4 & 1 & 2\\
\end{bmatrix}
\to
\begin{bmatrix}
1 & 2 & 1 & 2\\
0 & 2 & -2 & 6\\
0 & 0 & 5 & -10\\
\end{bmatrix}
$$

有了三角形式的增广矩阵，我们就可以从最后一个方程开始，由下往上依次将未知数带入到方程组中，求解出未知数，最后这个代入并求解的过程，叫做回代。

### 矩阵乘法的列视角和行视角

根据上述内容，矩阵 A 乘以一个列向量 b ，实际上是A 的列向量的线性组合，以 b 的各分量为系数，最终得到一个列向量。

**站在行视角来看，一个行向量 r 乘以矩阵 A ，实际上是 A 的行向量的线性组合，以 r 的各分量为系数，最终得到一个行向量。**

为什么这里要提出矩阵乘法的行视角呢？因为上述消元法实际上是对矩阵的行做线性组合，因此，利用矩阵乘法的行视角，我们可以将消元法表示为一个矩阵乘法的形式。

上一节中的一系列消元步骤，可以表示为：

$$\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -2 & 1 \\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0 \\
-3 & 1 & 0 \\
0 & 0 & 1 \\
\end{bmatrix}
\begin{bmatrix}
1 & 2 & 1 \\
3 & 8 & 1 \\
0 & 4 & 1 \\
\end{bmatrix}
=
\begin{bmatrix}
1 & 2 & 1 \\
0 & 2 & -2 \\
0 & 0 & 5 \\
\end{bmatrix}$$

左侧的两个矩阵称为**初等矩阵**（Elementary Matrix）或消元矩阵（Elimination Matrix），记作 $E$，它表示对矩阵做了一次行操作/行变换，$E_{ij}$ 表示要消去原矩阵第 i 行、第 j 列的元素。

（假设有一个矩阵乘法 AB = C，现在已知 B 和 C，要求出 A，站在列的视角，可以将 A 视为一组新的基向量，站在行的视角，可以将 A 是为对 B 做一系列行变换的矩阵，这两种方法都能快速得到A）。

置换矩阵（Permutation Matrix）是一种特殊的初等矩阵，用于交换矩阵的行或列，交换单位矩阵的对应行即可得到置换矩阵。

**两个矩阵相乘，左侧矩阵是对右侧矩阵做行变换，右侧矩阵是对左侧矩阵做列变换。**

（注意，这里提到的行变换和列变换是针对整个矩阵而言的，而线性变换是针对向量而言的。）

矩阵乘法满足结合律，但不满足交换律。

## 矩阵乘法和逆

### 矩阵乘法

矩阵乘法 AB = C 的五种计算方法：

1. 对 A 的单行和 B 的单列做点积
2. 将 AB = C 视为 A 的列向量的线性组合，B 的每一列是 C 的对应列的系数
3. 将 AB = C 视为 B 的行向量的线性组合，A 的每一行是 C 的对应行的系数
4. 对 A 的单列和 B 的单行做矩阵乘法，然后对所有结果求和，假设 A 有 n 列，B 有 n 行，那么结果是对 n 个矩阵求和。
5. 分块乘法。

以下是方法 4 的一个例子：

$$
\begin{bmatrix}
2 & 7 \\
3 & 8 \\
4 & 9 \\
\end{bmatrix}
\begin{bmatrix}
1 & 6 \\
0 & 0 \\
\end{bmatrix}
=
\begin{bmatrix}
2 \\
3 \\
4 \\
\end{bmatrix}
\begin{bmatrix}
1 & 6 \\
\end{bmatrix}
+
\begin{bmatrix}
7 \\
8 \\
9 \\
\end{bmatrix}
\begin{bmatrix}
0 & 0 \\
\end{bmatrix}
$$

先来看单列和单行相乘的结果：

$$
\begin{bmatrix}
2 \\
3 \\
4 \\
\end{bmatrix}
\begin{bmatrix}
1 & 6 \\
\end{bmatrix}
=
\begin{bmatrix}
2 & 12 \\
3 & 18 \\
4 & 24 \\
\end{bmatrix}
$$

实际上是对左边的列向量或右边的行向量做了按倍数放大操作，这些向量的方向都是同一方向，而且没有发生变化，**这个矩阵的行空间和列空间都在同一条直线上**。

### 矩阵的逆（Inverse）

$A^{-1}A = I$

如果 A 是方阵，则 $AA^{-1} = I$

A 叫做可逆矩阵或非奇异矩阵。

逆矩阵不一定存在。

判断一个矩阵是否可逆（例如 
$A = \begin{bmatrix}
1 & 2 \\
3 & 6 \\
\end{bmatrix}$
）有以下方法：

1. 行列式为0，则矩阵不可逆
2. 考虑是否存在一个矩阵和它相乘能够得到一个单位矩阵，由于它是个方阵，既可以考虑把它放在左边的情况，也可以考虑放在右边的情况。
3. 考虑是否存在一个非零向量x，使得 Ax = 0 ，如果存在这样的非零向量x，则矩阵A不可逆。一方面从线性方程组的角度来看，如果 A 可逆，它的主元数量应该等于未知数的数量，Ax = 0 只有零解，x 不会是非零向量，另一方面，从线性组合的角度来看，一个可逆的矩阵，它的列向量是线性无关的，不可能通过线性组合得到零向量，除非所有系数都是零。如果 A 存在逆矩阵，可以在方程 Ax = 0 左右两侧同时乘以 A的逆，只能得到 x = 0。

**一个不可逆的、奇异的矩阵，它的列向量是线性相关的，可以通过线性组合得到零向量，这意味着 Ax = 0 存在非零解 x**。

如果要求一个矩阵的逆，可以利用 $AA^{-1} = I$ 将问题转化为 求 $AX = I$ 的问题，其中 X 是未知矩阵，可以将 I 看作是多个列向量组成的矩阵，然后对每个列向量分别求解线性方程组 $Ax = e_i$，其中 $e_i$ 是 I 的一个列向量，最终将所有的解组合成矩阵 X 即可。

**高斯-约旦消元法（Gauss-Jordan Elimination）**也可以用来求矩阵的逆，具体做法是将矩阵 A 和单位矩阵 I 拼接成增广矩阵 [A | I]，然后对增广矩阵做行变换，直到左侧的 A 变成单位矩阵，此时右侧的矩阵就是 A 的逆矩阵 $A^{-1}$（其实就是上面求解多个线性方程组方法的简化版）。

高斯-约旦消元法可以很容易地从求解线性方程组的角度来理解，还有一种理解方式，假设 $[A | I] \to [I | A']$ 这个变换是由 $E$ 实现的，即 $E[A | I] = [I | A']$，那么根据矩阵分块乘法，$EA = I$，$EI = A'$，很容易就能得到 $A' = A^{-1}$。

**两个矩阵相乘的逆**，$(AB)^{-1} = B^{-1}A^{-1}$，这很容易证明，$(AB)(AB)^{-1} = I, (AB)(B^{-1}A^{-1}) = A(BB^{-1})A^{-1} = AIA^{-1} = AA^{-1} = I$，这个性质也很容易理解，从线性变换的角度来看，先做 B 变换，再做 A 变换，那么要想倒回去，必须先做 A 的逆变换，再做 B 的逆变换。

**矩阵的逆与转置（Transpose） **满足 $(A^T)^{-1} = (A^{-1})^T$， 证明也很简单，$AA^{-1} = I = I^T = (AA^{-1})^T = (A^{-1})^TA^T$，由 $(A^{-1})^TA^T  = I$ 可以得到 $A^T$ 和 $(A^{-1})^T$ 互为逆。这里用到一个转置性质：$(AB)^T = B^TA^T$。

## 矩阵分解（A = LU）

### 怎么分解

假如 2x2 矩阵 A 通过一次行变换 $E_{21}$ 消元，变成了上三角矩阵 U，即 $E_{21}A = U$，现在我们想知道如何从 U 反向变回 A，也就是存在一个 L 使得 A = LU，L 是 $E_{21}$ 的逆矩阵。（U 是个上三角矩阵，L 是个下三角矩阵）

例如：

$$
A =
\begin{bmatrix}
2 & 1 \\
8 & 7 \\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 \\
4 & 1 \\
\end{bmatrix}
\begin{bmatrix}
2 & 1 \\
0 & 3 \\
\end{bmatrix}
=
\begin{bmatrix}
1 & 0 \\
4 & 1 \\
\end{bmatrix}
\begin{bmatrix}
2 & 0 \\
0 & 3 \\
\end{bmatrix}
\begin{bmatrix}
1 & \frac{1}{2} \\
0 & 1 \\
\end{bmatrix}
$$

$$
L=
\begin{bmatrix}
1 & 0 \\
4 & 1 \\
\end{bmatrix},
E=
\begin{bmatrix}
1 & 0 \\
-4 & 1 \\
\end{bmatrix},
L = E^{-1}
$$

上面这个例子不仅将 A 分解成了 LU 的形式，还进一步分解成了 LDU 的形式，其中 D 是一个对角矩阵。

如果 A 是 3x3 矩阵，会复杂一些，$E_{32}E_{31}E_{21}A = U, A = L U，L = E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}$。

假设有一个 3x3 矩阵 A，它的第三行第一列元素为0，那么它在消元时只需要做两次行变换 $E_{32}E_{21}A = U$，对应的 L 矩阵为 $L = E_{21}^{-1}E_{32}^{-1}$，如下所示：

$$
E_{32}E_{21}=
\begin{bmatrix}1&0&0\\0&1&0\\0&-5&1\end{bmatrix}
\begin{bmatrix}1&0&0\\-2&1&0\\0&0&1\end{bmatrix}
= \begin{bmatrix}1&0&0\\-2&1&0\\10&-5&1\end{bmatrix}
= E
$$

$$
E_{21}^{-1}E_{32}^{-1}=
\begin{bmatrix}1&0&0\\2&1&0\\0&0&1\end{bmatrix}
\begin{bmatrix}1&0&0\\0&1&0\\0&5&1\end{bmatrix}
= \begin{bmatrix}1&0&0\\2&1&0\\0&5&1\end{bmatrix}
= L
$$

我们发现一个问题，虽然我们没有做 $E_{31}$ 这个行变换，但是 E 矩阵的第三行第一列元素并不是0，**而 L 矩阵的好处在于，它的元素中只会把消元时用到的乘数（消元过程中需要乘以并减去的那个倍数）记录下来，其他位置的元素都是0或1（前提是没有行交换这种变换），换句话说，只要我知道所有的消元乘数，就能快速得到 L**。

### 消元的计算复杂度

一个 nxn 矩阵消元，如果对一个元素做一次乘法和减法算一次操作，总共进行了多少次消元操作？

假设矩阵中的所有的非主元都不为0，都需要消元，如果要把第一列所有的非主元都消掉，那么矩阵中除了第一行之外的所有行都需要做一次消元操作，因此总共有 n(n-1) 个元素会发生变化，以此类推，把第二列的所有非主元都消掉，共有 (n-1)(n-2) 个元素会发生变化，我们把计算简化一下，把 n(n-1) 视为 $n^2$，把(n-1)(n-2) 视为 $(n-1)^2$，总的操作次数大约有 $n^2 + (n-1)^2 + ... + 1$ 这么多次，整体为 $n^3$ 这个量级，实际大约是 $\frac{1}{3}n^3$（直接对 $x^2$ 求积分可以得出，级数可以理解为用宽度为1的矩形和去对积分做近似）。

### 行交换、置换和转置

**置换和转置**

现在我们把行交换也考虑进去，当某一行的主元为 0 时，就需要行交换，行交换需要使用置换矩阵。

前面讲过，置换矩阵实际上是把单位矩阵的行交换得到的矩阵，3x3 矩阵的置换矩阵有 6 种，如果这 6 个置换矩阵互相相乘，得到的新矩阵仍然是这6 个置换矩阵中的一个，也就是说这 6 个置换矩阵在矩阵乘法下构成了一个群。

（注意，这 6 个置换矩阵可不都是仅交换两行的，有可能一个置换矩阵交换了多行，它们都是对行的重排列）

一个 nxn 的矩阵有 n! 种置换矩阵，即 $A_{n}^{n}$ 种行排列方式。

用 P 表示置换矩阵，上节中的矩阵分解可以表示为一般形式 PA = LU，用来包括消元时需要做行交换的情况。

置换矩阵的逆就是它的转置，$P^{-1} = P^T$，这也意味着 $P^TP = I$

**对称和转置**

对称矩阵（Symmetric Matrix）满足 $A = A^T$，对称矩阵的逆矩阵也是对称矩阵，很容易证明，$A^{-1} = (A^T)^{-1} = (A^{-1})^T$。

任意一个矩阵和它的转置相乘（$A^TA$）就可以得到一个对称矩阵，可以这样证明，$(A^TA)^T = A^T(A^T)^T = A^TA$。 

## 向量空间

### 向量空间

**标量和向量**，标量就是一个数，向量是一个有方向和大小的量，可以用有序数组表示。

$R^2$ 就是一个**向量空间**，它表示所有二维实向量的集合。

向量空间必须对数乘和加法这两种运算封闭（对线性组合封闭）

### 子空间（Subspace）

**子空间**也必须满足对数乘和加法这两种运算封闭。

例如，在 $R^2$ 中，一条过原点的直线就是一个子空间，因为这条直线上的所有向量都对数乘和加法封闭，如果这条直线不过原点，那它就不是子空间。

实际上，$R^2$ 有三种子空间，（1）它本身，（2）过原点的直线，（3）零点。

$R^3$ 有四种子空间，（1）它本身，（2）过原点的平面，（3）过原点的直线，（4）零点。

如果从一个 n 行矩阵 A 的列向量出发构造子空间，A 的列向量的所有线性组合会构成一个 $R^n$ 的子空间，这个子空间称为**列空间**，用 $C(A)$ 表示。

在 $R^3$ 中，两个线性无关的列向量构成的列空间是一个过原点的平面。

如果是两个共线的向量，它们构成的列空间就是一条过原点的直线。

两个子空间的并集不一定是一个新的子空间。

**两个子空间的交集仍然是一个子空间**，因为交集中的向量必然同时属于两个子空间，它们数乘和相加后的结果也必然属于两个子空间，也就是说，数乘和相加后的结果仍在交集之中。

### 列空间（Column Space）

一个 mxn 矩阵，例如一个 4x3 矩阵 A，A 的列向量本身位于 $R^4$ 中，它的列空间 $C(A)$ 是 $R^4$ 的一个子空间。

**我们把它和线性方程组 Ax = b 联系起来看，b 必须位于 A 的列空间 $C(A)$ 中，方程组才有解**。

例子中，对于任意的b，Ax = b 并不是都有解，它有四个方程，但只有三个未知数，三个列向量的线性组合最多只能张成一个三维空间，无法覆盖整个四维空间，因此，只有当 b 是 A 的列向量的线性组合时，Ax = b 才有解。

如果 A 的三个列向量是线性相关的，只有两个线性无关的列向量，那么能表示的 b 就更少了，我们把两个线性无关向量称为主列，它们张成的子空间是 $R^4$ 的一个二维子空间。

### 零空间（Null Space）

当 b 为 0 向量时，方程组变成 Ax = 0 ，**零空间是由 Ax = 0 所有的解 x 组成的子空间**，记作 $N(A)$。

（要构成子空间，一个解做完数乘和加法后仍然是方程的解，稍微琢磨一下就知道，Ax = 0 的全体解必然是构成一个子空间的。）

以上面的 4x3 矩阵 A 为例，方程中中有四个方程，而未知数只有三个，因此 A 的列空间 $C(A)$ 是 $R^4$ 的一个子空间，零空间 $N(A)$ 是 $R^3$ 的一个子空间。

零向量必然在零空间中。

把 Ax = 0 换成 Ax = b，它的解不构成一个子空间（最基本地，解中连零向量都不包含）。

向量空间需要穿过零点，不过零点不是向量空间。

注意，列空间是由列向量出发张成的，而零空间是由全体解向量组成的，我们最开始并不知道里面有哪些向量，只能通过解方程组来找到这些向量，**这是两种不同的子空间构造方式**。

## Ax = 0

### 特解

考虑这样一个 Ax = 0

$$
A=
\begin{bmatrix}
1 & 2 & 2 & 2 \\
2 & 4 & 6 & 8 \\
3 & 6 & 8 & 10
\end{bmatrix}
$$

消元之后会得到

$$
U=
\begin{bmatrix}
1 & 2 & 2 & 2 \\
0 & 0 & 2 & 4 \\
0 & 0 & 0 & 0
\end{bmatrix}
$$

可以看到只有两个主元，我们把两个主元称为矩阵的**秩（Rank）**为 2。

从 Ax=0 到 Ux=0，解空间（零空间）不会变。

（前面提到，矩阵中线性无关的列叫主列，我们可以观察到，消元结束后，主元所在的列就是主列。）

我们把主元所在的列称作主列（Pivot Column），没有主元的列称作自由列（Free Column）。

自由列对应的未知数的值可以随便取值，然后我们肯定能给主元对应的未知数找到两个值，从而求出方程的解，一组特定的自由变量称为**特解**。

此时，只要找到两个线性无关的特解，就能将解写成两个特解的线性组合的形式，张成零空间。

### 如何取特解

**简化行阶梯形矩阵**（Reduced Row Echelon Form, RREF）是指每个主元都是1，并且主元所在列的其他元素都是0的矩阵。

对于上面的例子，简化行阶梯形矩阵为：

$$
R=
\begin{bmatrix}
1 & 2 & 0 & -2 \\
0 & 0 & 1 & 2 \\
0 & 0 & 0 & 0
\end{bmatrix}
$$

把 R 矩阵列的顺序调整一下，使得 R 变成以下形式：

$$
R=
\begin{bmatrix}
1 & 0 & 2 & -2 \\
0 & 1 & 0 & 2 \\
0 & 0 & 0 & 1
\end{bmatrix}
=
\begin{bmatrix}
I & F \\
0 & 0
\end{bmatrix}
$$

左侧是由主列构成的单位矩阵，右侧是由自由列构成的矩阵 F。

现在求解 Rx = 0 变成了求解 RN = 0，N 代表零空间矩阵（即 N 的列可以张成整个零空间）。

很容易得到

$$
N =
\begin{bmatrix}
-F \\
I
\end{bmatrix}
$$

（我们能够注意到，Ax = 0求特解实际上就是求一组零空间的基，有几个自由变量，就有几个基向量）

## Ax = b

### 求解 Ax = b

Ax = b 可能无解，可能有唯一解，可能有无穷多解。

还是以上面的例子为例，加上 b 之后，可以得到一个增广矩阵

$$
\left[
\begin{array}{cccc|c}
1 & 2 & 2 & 2 & b_{1} \\
2 & 4 & 6 & 8 & b_{2} \\
3 & 6 & 8 & 10 & b_{3}
\end{array}
\right]
$$

消元后，

$$
\left[
\begin{array}{cccc|c}
1 & 2 & 2 & 2 & b_{1} \\
0 & 0 & 2 & 4 & b_{2}-2b_{1} \\
0 & 0 & 0 & 0 & b_{3}-b_{2}-b_{1}
\end{array}
\right]
$$

并且由于第三行都为0，所以有 $0 = b_{3}-b_{2}-b_{1}$。

**b 的可解性条件（Solvability Condition）**的两种等价描述：

站在列的角度：b 必须属于 A 的列空间。

站在行的角度：如果消元后有一行是全0（例如上面的情况），b 变换后对应的分量必须为0，这个分量实际上是 b 原分量的线性组合。

**求解 Ax = b**

继续上面的例子，先找特解，将所有自由变量设为0，求出一个特解 $x_{p}$，然后再在零空间内找一个任意的解 $x_{n}$，最终的解可以表示为 $x = x_{p} + x_{n}$。

通解为 $x = x_{p} + c_1n_1 + ... + c_nn_n$，即特解加上零空间的线性组合。

上面的例子得到的通解为：

$$
x =
\begin{bmatrix}
-2 \\ 0 \\ \frac{3}{2} \\ 0
\end{bmatrix}
+ c_{1}
\begin{bmatrix}
-2 \\ 1 \\ 0 \\ 0
\end{bmatrix}
+ c_{2}
\begin{bmatrix}
2 \\ 0 \\ -2 \\ 1
\end{bmatrix}
$$

这个通解所代表的一系列向量，并不能构成一个子空间，因为它们并不包含零向量，如果不包含最左边那个特解，剩下的部分是 Ax = b 的零空间（即 Ax = 0 的解空间），它是一个过原点的平面，加上特解以后，相当于整个平面朝着特解的方向整体平移了一段距离。

### mxn 矩阵

考虑秩为 r 的 mxn 矩阵 A，主元个数不可能超过行数 m 和列数 n，即，

$$ r \leqslant m, r \leqslant n$$

**列满秩**

考虑列满秩的情况（r=n，m>n），列全部线性无关，没有自由变量，零空间只有零向量（Ax = 0只有零解），Ax = b 有解时只有唯一解，或者无解（方程只有 0 个解或 1 个解）。

此时，

$$
R=
\begin{bmatrix}
I \\
0
\end{bmatrix}
$$

**行满秩**

考虑行满秩的情况（r=m，n>m），Ax = b 有无穷多解，对任意的 b，Ax = b 都有解。

此时，

$$
R=
\begin{bmatrix}
I & F
\end{bmatrix}
$$

**行列都满秩**

r = m = n，A 是一个方阵，并且是可逆矩阵，Ax = b 对任意的 b 都有唯一解。

此时，

$$
R=
\begin{bmatrix}
I
\end{bmatrix}
$$

**行列都不满秩**

r < m，r < n，Ax = b 有无穷多解或无解，不可能有唯一解。

此时，

$$
R=
\begin{bmatrix}
I & F \\
0 & 0
\end{bmatrix}
$$

## 线性相关

线性相关（Linear Dependence）、线性无关（Linear Independence）、基（Basis）、维度（Dimension）

Ax = 0 存在非零解的原因是，A 消元后存在自由变量，A 的列向量是线性相关的。

假设 A 中存在一个全 0 的列，那么 A 的列向量的线性组合中全 0 列的系数可以是任意的，Ax = 0 会存在无穷多个解。

当矩阵的零空间中只有零向量时，A 的列向量是线性无关的。

如果 mxn 矩阵的列是线性无关的，矩阵的秩 r = n，秩代表线性无关的列向量的个数。

生成/张成（Span），两个线性无关的向量的线性组合可以张成一个平面。

基向量：一组线性无关的向量，并且张成一个空间，基向量的个数称为空间的维度。

对于矩阵 A，列空间的维数是线性无关的列向量的个数，即矩阵的秩 r（列空间的维数和行数无关）。

**零空间的维数是自由变量的个数，即 n - r**，Ax = 0 有几个自由向量，就有几个特解。

## 四个基本子空间

列空间 C(A)、零空间 N(A)、行空间（A转置的列空间） C(A^T)、左零空间（A转置的零空间） N(A^T)。

假设 A 为 mxn 矩阵，零空间 N(A) 是 $R^n$ 的子空间，列空间 C(A) 是 $R^m$ 的子空间，行空间 C(A^T) 是 $R^n$ 的子空间，左零空间 N(A^T) 是 $R^m$ 的子空间。

